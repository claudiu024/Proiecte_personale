{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\Users\\Claudiu\\mambaforge\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\Users\\Claudiu\\mambaforge\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\Users\\Claudiu\\mambaforge\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\Users\\Claudiu\\mambaforge\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\Users\\Claudiu\\mambaforge\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\Users\\Claudiu\\mambaforge\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Banknote authentication dataset example \n",
      "\n",
      "Loading data into memory \n",
      "[[0.35567322 0.61110795 0.43351611 0.20657583 0.477737   0.04220629]\n",
      " [0.12741129 0.24461868 0.26514736 0.17564361 0.5133559  0.02930886]\n",
      " [0.28639668 0.6383572  0.3883895  0.12612043 0.5724287  0.03142521]\n",
      " ...\n",
      " [0.4514367  0.4711969  0.5419044  0.37026435 0.44254383 0.02676807]\n",
      " [0.40955412 0.39015022 0.5650486  0.3716718  0.573712   0.11689572]\n",
      " [0.16448937 0.47275075 0.24209106 0.09414084 0.5889282  0.01807188]]\n",
      "Creating 4-(8-8)-1 binary NN classifier \n",
      "\n",
      "epoch =    0  loss = 0.583952  acc = 72.43%\n",
      "epoch =   50  loss = 0.545912  acc = 72.43%\n",
      "epoch =  100  loss = 0.519515  acc = 71.19%\n",
      "epoch =  150  loss = 0.499255  acc = 74.07%\n",
      "epoch =  200  loss = 0.482440  acc = 77.37%\n",
      "epoch =  250  loss = 0.469480  acc = 78.60%\n",
      "epoch =  300  loss = 0.459642  acc = 77.78%\n",
      "epoch =  350  loss = 0.449080  acc = 78.60%\n",
      "epoch =  400  loss = 0.438831  acc = 79.42%\n",
      "epoch =  450  loss = 0.429007  acc = 81.89%\n",
      "epoch =  500  loss = 0.419470  acc = 82.72%\n",
      "epoch =  550  loss = 0.409764  acc = 81.89%\n",
      "epoch =  600  loss = 0.399927  acc = 83.95%\n",
      "epoch =  650  loss = 0.390434  acc = 83.13%\n",
      "epoch =  700  loss = 0.381519  acc = 83.54%\n",
      "epoch =  750  loss = 0.373425  acc = 85.60%\n",
      "epoch =  800  loss = 0.363042  acc = 84.77%\n",
      "epoch =  850  loss = 0.355088  acc = 84.77%\n",
      "epoch =  900  loss = 0.346876  acc = 84.77%\n",
      "epoch =  950  loss = 0.339954  acc = 85.19%\n",
      "\n",
      "Loss, accuracy on test data: \n",
      "0.3808 82.69%\n",
      "\n",
      "Predicting normal vertebral column for: \n",
      "[[0.5 0.5 0.5 0.5 0.5 0.5]]\n",
      "Probability that class = 1 (normal):\n",
      "[[0.000689]]\n"
     ]
    }
   ],
   "source": [
    "#working on python 3.6.15\n",
    "# Vertebral column classification\n",
    "# Keras 2.1.5 TensorFlow 1.7.0 Anaconda3 4.1.1\n",
    "# raw data looks like:\n",
    "\n",
    "#81.75441933,20.12346562,70.56044038,61.63095371,119.4250857,55.50688907,0\n",
    "#51.31177106,8.875541276,56.99999999,42.43622979,126.4722584,-2.144043911,1\n",
    "\n",
    "# Abstract: Data set containing values for six biomechanical features used to classify orthopaedic patients \n",
    "# 2 classes (normal or abnormal).\n",
    "# 0 = abnormal, 1 = normal\n",
    "\n",
    "#biomechanical feautures:\n",
    "# @attribute pelvic_incidence numeric\n",
    "# @attribute pelvic_tilt numeric\n",
    "# @attribute lumbar_lordosis_angle numeric\n",
    "# @attribute sacral_slope numeric\n",
    "# @attribute pelvic_radius numeric\n",
    "# @attribute degree_spondylolisthesis numeric\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import keras as K\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'  # suppress CPU msg\n",
    "\n",
    "class MyLogger(K.callbacks.Callback):\n",
    "  def __init__(self, n):\n",
    "    self.n = n   # print loss & acc every n epochs\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if epoch % self.n == 0:\n",
    "      curr_loss =logs.get('loss')\n",
    "      curr_acc = logs.get('acc') * 100\n",
    "      print(\"epoch = %4d  loss = %0.6f  acc = %0.2f%%\" % \\\n",
    "        (epoch, curr_loss, curr_acc))\n",
    "\n",
    "def main():\n",
    "  print(\"\\nVerify if spine is normal dataset example \\n\")\n",
    "  np.random.seed(1)\n",
    "\n",
    "  # 1. load data\n",
    "  print(\"Loading data into memory \")\n",
    "  train_file = \"train.txt\"\n",
    "  test_file = \"test.txt\"\n",
    "\n",
    "  train_x = np.loadtxt(train_file, delimiter=',',\n",
    "    usecols=[0,1,2,3,4,5], dtype=np.float32)\n",
    "  train_y = np.loadtxt(train_file, delimiter=',',\n",
    "    usecols=[6], dtype=np.float32)\n",
    "  test_x = np.loadtxt(test_file, delimiter=',', \n",
    "    usecols=[0,1,2,3,4,5], dtype=np.float32)\n",
    "  test_y =np.loadtxt(test_file, delimiter=',',\n",
    "    usecols=[6], dtype=np.float32)\n",
    "\n",
    "  \n",
    "  norm_train_X=[]\n",
    "\n",
    "  norm_test_X=[]\n",
    "\n",
    "  \n",
    "  for i in range (len(train_x[0])):\n",
    "    norm_train_X.append((train_x[:,i]-min(train_x[:,i])) / (max(train_x[:,i])-min(train_x[:,i])))\n",
    "    norm_test_X.append((test_x[:,i]-min(test_x[:,i])) / (max(test_x[:,i])-min(test_x[:,i])))\n",
    " \n",
    "  t_norm_train_X=np.array(norm_train_X).transpose()\n",
    "  t_norm_test_X=np.array(norm_test_X).transpose()\n",
    "  print(t_norm_train_X)\n",
    "\n",
    "  # 2. define 4-(x-x)-1 deep NN model\n",
    "  print(\"Creating 4-(8-8)-1 binary NN classifier \\n\")\n",
    "  my_init = K.initializers.glorot_uniform(seed=1)\n",
    "  model = K.models.Sequential()\n",
    "  model.add(K.layers.Dense(units=8, input_dim=6,\n",
    "    activation='tanh', kernel_initializer=my_init)) \n",
    "  model.add(K.layers.Dense(units=8, activation='tanh',\n",
    "    kernel_initializer=my_init)) \n",
    "  model.add(K.layers.Dense(units=1, activation='sigmoid',\n",
    "    kernel_initializer=my_init)) \n",
    "\n",
    "  # 3. compile model\n",
    "  simple_sgd = K.optimizers.SGD(lr=0.01)  \n",
    "  model.compile(loss='binary_crossentropy',\n",
    "    optimizer=simple_sgd, metrics=['accuracy'])  \n",
    "\n",
    "  # 4. train model\n",
    "  max_epochs = 1000\n",
    "  my_logger = MyLogger(n=50)\n",
    "  h = model.fit(t_norm_train_X, train_y, batch_size=32,\n",
    "    epochs=max_epochs, verbose=0, callbacks=[my_logger]) \n",
    "\n",
    "  # 5. evaluate model\n",
    "  np.set_printoptions(precision=6, suppress=True)\n",
    "  eval_results = model.evaluate(t_norm_test_X,test_y, verbose=0) \n",
    "  print(\"\\nLoss, accuracy on test data: \")\n",
    "  print(\"%0.4f %0.2f%%\" % (eval_results[0], \\\n",
    "eval_results[1]*100))\n",
    "\n",
    "  # 6. save model\n",
    "  # mp = \".\\\\Models\\\\vcolumn_model.h5\"\n",
    "  # model.save(mp)\n",
    "\n",
    "  # 7. make a prediction\n",
    "  inpts = np.array([[0.5, 0.5, 0.5, 0.5,0.5,0.5]], dtype=np.float32)\n",
    "  pred = model.predict(inpts)\n",
    "  print(\"\\nPredicting normal vertebral column for: \")\n",
    "  print(inpts)\n",
    "  print(\"Probability that class = 1 (normal):\")\n",
    "  print(pred)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "  main()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38288b4690c7fca0884686b2cb3df1e38d572a2a456033324276c3b36d22a75b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('py36')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
